{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation Library, global variable and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.io.json._normalize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3724882563fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrendReq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpyo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnested_to_record\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murllib3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRetry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas.io.json._normalize'"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "from scipy import signal\n",
    "import scipy.cluster.hierarchy as spc\n",
    "from pandas import read_excel\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import interactive, HBox, VBox\n",
    "import plotly.io as pio\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = [\"FR\",\"BE\",\"BG\",\"CY\",\"CZ\",\"DE\",\"DK\",\"EE\",\"ES\",\"FI\",\"AT\",\"GB\",\"GR\",\"HR\",\"HU\",\"IE\",\"IT\",\"LT\",\"LU\",\"LV\",\"MT\",\"NL\",\"PL\",\"PT\",\"RO\",\"SE\",\"SI\",\"SK\"]\n",
    "country_list_iso = [\"FRA\",\"BEL\",\"BGR\",\"CYP\",\"CZE\",\"DEU\",\"DNK\",\"EST\",\"ESP\",\"FIN\",\"AUT\",\"GBR\",\"GRC\",\"HRV\",\"HUN\",\"IRL\",\"ITA\",\"LTU\",\"LUX\",\"LVA\",\"MLT\",\"NLD\",\"POL\",\"PRT\",\"ROU\",\"SWE\",\"SVN\",\"SVK\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster countries based on correlation measure\n",
    "def getIdx(corr,variableTweak):\n",
    "    pdist = spc.distance.pdist(corr)\n",
    "    linkage = spc.linkage(pdist, method='complete')\n",
    "    idx = spc.fcluster(linkage, variableTweak * pdist.max(), 'distance')\n",
    "    return idx\n",
    "\n",
    "def getGroupe(number,idx):\n",
    "    groupe = []\n",
    "    for i in range(0,len(idx)):\n",
    "        x = idx[i]\n",
    "        if x == number:\n",
    "            groupe.append(i)\n",
    "    return groupe\n",
    "\n",
    "def plotDifferentGroup(idx,dfPlot,indicePlot, title):\n",
    "    for i in range(1,max(idx)+1):\n",
    "        df1 = dfPlot[dfPlot.columns[getGroupe(i,idx)]]\n",
    "        plot_lines(df1,indicePlot, title)\n",
    "\n",
    "def plotMapStatic(idx, title):\n",
    "    fig = go.Figure(data=go.Choropleth(\n",
    "        locations=country_list_iso, # Spatial coordinates\n",
    "        z = idx, # Data to be color-coded\n",
    "        locationmode = 'ISO-3', # set of locations match entries in `locations`\n",
    "        colorscale=\"Blugrn\",\n",
    "        colorbar_title = \"Millions USD\",\n",
    "        showscale = False,\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text = title,\n",
    "        geo_scope='europe', # limite map scope to USA\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=800,\n",
    "        dragmode=False\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "def plotByGroup(df, title, threshold=0.5, method='hierarchical', n_clusters=3):\n",
    "    df_corr= df.corr(method='kendall')\n",
    "    idx = None\n",
    "    if method== 'hierarchical':\n",
    "        idx = getIdx(df_corr, threshold)\n",
    "    else:\n",
    "        idx=getKMeansGroups(df, n_clusters)+1\n",
    "    plotDifferentGroup(idx, df, 11, title)\n",
    "    plotMapStatic(idx, 'Clustering by interest on subject')\n",
    "    \n",
    "    \n",
    "def getKMeansGroups(df, n_clusters=3):\n",
    "    k_means = KMeans(n_clusters=n_clusters, random_state=0).fit(df.transpose().values)\n",
    "    return k_means.predict(df.transpose().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lines(df,value_smooth, title):\n",
    "    fig = go.Figure()\n",
    "    for x in df.columns:\n",
    "        if value_smooth == 0:\n",
    "            fig.add_trace(go.Scatter(x=df.index, y=df[x], mode='lines',name=x))\n",
    "        else:\n",
    "            fig.add_trace(go.Scatter(x=df.index, y=signal.savgol_filter(df[x],value_smooth, 3), mode='lines',name=x))\n",
    "    fig.update_layout(title_text=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMapSlider(data,title,zMax,zMin,colorbarTitle,vWidth,vHeight):\n",
    "    data_slider = []\n",
    "    for ix in range(0,17):\n",
    "        data_one_year = dict(\n",
    "                            type='choropleth',\n",
    "                            locations=country_list_iso, # Spatial coordinates\n",
    "                            z = data[country_list].iloc[ix],\n",
    "                            locationmode = 'ISO-3', # set of locations match entries in `locations`\n",
    "                            autocolorscale=False,\n",
    "                            colorscale = \"Blugrn\",\n",
    "                            zmax = zMax,\n",
    "                            zmin = zMin,\n",
    "                            colorbar_title = colorbarTitle,\n",
    "                            )\n",
    "        ix = ix+1\n",
    "        data_slider.append(data_one_year) \n",
    "    steps = []\n",
    "\n",
    "    for i in range(len(data_slider)):\n",
    "        step = dict(method='restyle',args=['visible', [False] * len(data_slider)],label=data.index[i].strftime(\"%m/%d/%Y\"))\n",
    "        step['args'][1][i] = True\n",
    "        steps.append(step)\n",
    "\n",
    "    #create 'sliders' object from the 'steps' \n",
    "    sliders = [dict(active=0, pad={\"t\": 1}, steps=steps)] \n",
    "\n",
    "    layout = dict(geo=dict(scope='europe',),sliders=sliders,title_text = title,autosize=False, width=vWidth,height=vHeight,dragmode = False,)\n",
    "    fig = dict(data=data_slider, layout=layout,) \n",
    "    pio.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGlobalTrend(dfPlot,smooth,title):\n",
    "    new_dfPlot = dfPlot.copy()\n",
    "    new_dfPlot.loc[:,\"Total norm\"] = new_dfPlot.sum(axis=1)/new_dfPlot.shape[1]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    df = new_dfPlot.loc[:,\"Total norm\"]\n",
    "    if smooth == 0:\n",
    "        fig.add_trace(go.Scatter(x=df.index, y=df, mode='lines',name=x))\n",
    "    else:\n",
    "        fig.add_trace(go.Scatter(x=df.index, y=signal.savgol_filter(df,smooth, 3), mode='lines',name=\"Global\"))\n",
    "    fig.update_layout(title_text=\"Global tendancy Google search about Climate change/Global warming\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Meat Consumption in EU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project consist of studying meat consumption in Europe and impact on it depending on different factors that will be discussed later on.\n",
    "\n",
    "In order to complete that, we need to see how the 28 countries in the EU (European Union) consume meats (mutton/goat/poultry/beef/pig). \n",
    "Then, we will see how this consumption vary for some selected countries in the EU.\n",
    "\n",
    "We decide to work with datas between 2004 and 2019 (whenever it is possible).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Meat Consumption of the 28 EU countries\n",
    "\n",
    "Dataset used: https://data.oecd.org/agroutput/meat-consumption.htm\n",
    "\n",
    "Let's use the above dataset in order to see how fluctuates meat consumption in the 28 EU countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data_aslam/' # TODO: change path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_consumption_path = path + 'DP_LIVE_23112019095726322.csv'\n",
    "meat_consumption = pd.read_csv(meat_consumption_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove useless columns\n",
    "#  - column INDICATOR contains only 'MEATCONSUMP', so we can remove it\n",
    "#  - column Flag Codes contains only NaN, so we can remove it\n",
    "#  - column FREQUENCY contains only A's\n",
    "meat_consumption = meat_consumption.drop(columns = ['INDICATOR', 'Flag Codes', 'FREQUENCY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure are either in:\n",
    "- KG_CAP (Kilogram of retail weights per capita)\n",
    "- THND_TONNE (Thousand tonnes of carcass weights)\n",
    "\n",
    "We choose to take *KG_CAP*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_consumption = meat_consumption[meat_consumption['MEASURE'] == 'KG_CAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_consumption = meat_consumption[ (meat_consumption['TIME'] >= 2004) & (meat_consumption['TIME'] <= 2018)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the dataset separated the United Kingdom from the EU countries because of the BREXIT. Since we want to work with the 28 EU countries, we need to selected only **'EU27'** and **'GBR'** (Great Britain) and merge the values in order to plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_consumption = meat_consumption[ (meat_consumption['LOCATION'] == 'EU27') | (meat_consumption['LOCATION'] == 'GBR')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order combine 'EU27' and 'GBR', we need to take care of the proportionality between them. Indeed, if we just sum them, the displayed consumption will be the consumption of 1 citizen of EU27 additioned to the UK consumption which isn't what we want. \n",
    "To do that, we need to compute the ratio of British people among the 28 countries in EU and compute the adequate value to aggregate.\n",
    "\n",
    "We need the [population](http://appsso.eurostat.ec.europa.eu/nui/show.do?dataset=demo_gind&lang=fr) size on this period to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_EU28_2004_2019 = [492555798, 494598322, 496436597, 498300775, 500297033, 502090235, 503170618, 502964837, 504047749, 505163053, 507235091, 508520205, 510181874, 511373278, 512379225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_UK_2004_2019 = [59793759, 60182050, 60620361, 61073279, 61571647, 62042343, 62510197, 63022532, 63495088, 63905342, 64351203, 64853393, 65379044, 65844142, 66273576]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the ratio of the British people among the population in the EU28 (and EU27 among EU28):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UK_2004_2019_ratio = [x/y for x,y in zip(population_UK_2004_2019, population_EU28_2004_2019)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_EU27_2004_2019_ratio = [(x-y)/x for x,y in zip(population_EU28_2004_2019,population_UK_2004_2019)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio(row):\n",
    "    \"\"\"This function returns the correct ratio for a row depending on LOCATION and year\"\"\"\n",
    "    if row['LOCATION'] == 'EU27':\n",
    "        val = population_EU27_2004_2019_ratio[row['TIME'] - 2004]\n",
    "    elif row['LOCATION'] == 'GBR':\n",
    "        val = UK_2004_2019_ratio[row['TIME'] - 2004]\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_consumption['ratio'] =  meat_consumption.apply(ratio, axis=1)\n",
    "meat_consumption['Value'] = meat_consumption['ratio'] * meat_consumption['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_consumption = meat_consumption.groupby(['TIME', 'SUBJECT'])['Value'].sum().unstack(level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the overall consumption of meat (all meats mixed), we need to sum their quantities (since we just adapted the values with their appropriate ratios). \n",
    "\n",
    "\n",
    "Meanwhile, we need to take care about a fact:\n",
    "\n",
    "[\"Carcass weight to retail weight conversion factors are: 0.7 for beef and veal, 0.78 for pigmeat, and 0.88 for both sheep meat and poultry meat.\"](https://data.oecd.org/agroutput/meat-consumption.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_consumption['all_consumption'] = ( \n",
    "                                    (0.7 * meat_consumption['BEEF']) +\n",
    "                                    (0.78 * meat_consumption['PIG']) +\n",
    "                                    (0.88 * (meat_consumption['SHEEP'] + meat_consumption['POULTRY'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_consumption['years'] = meat_consumption.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(meat_consumption, x='years', y='all_consumption')\n",
    "fig.update_xaxes(title_text='Years')\n",
    "fig.update_yaxes(title_text='Meat consumption (Kg/capita)')\n",
    "fig.update_layout(title_text = 'Meat consumption of the 28 EU countries over the years',)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that before 2007, the consumption increases and then drop until 2013.\n",
    "Then, meat consumption drastically increases until 2018.\n",
    "\n",
    "However, it could be interesting to see the trends specifically for some countries to have a closer look at the consumption changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Variation for some selected countries in EU\n",
    "\n",
    "In order to get more details about the meat consumption in EU, we need to have a look per country.\n",
    "\n",
    "There is a [dataset (FAO)](http://www.fao.org/faostat/en/?#data/FBS/visualize) that contains such data for every country in the EU but only before 2013.\n",
    "\n",
    "Hence, we decide to find data for some selected countries from 2004 to 2018 elsewhere to compare them.\n",
    "\n",
    "We will use the **kg/person** unit to compare the consumption to avoid getting disturbed by the size of the population for the countries.\n",
    "\n",
    "We will first see the meat consumption for these countries and then see the variation considering 2004 as the base value and see how the consumption changed (compared to 2004).\n",
    "\n",
    "Let's do it with the following countries:\n",
    "- United Kingdom\n",
    "- Germany\n",
    "- Portugal\n",
    "- France\n",
    "- Slovakia\n",
    "- Slovenia\n",
    "- Sweden\n",
    "- Poland\n",
    "\n",
    "and then we will see the meat consumption of these countries over time and their variation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(The following function will be used to compute variation between years from 2004. It returns the base value:)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the first value the dataset (2004)\n",
    "def  get_value_of_2004(df):\n",
    "    return df[ (df['years'] == 2004)]['meat consumption (kg/person)'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 UK meat consumption (United Kingdom)\n",
    "\n",
    "As you saw before, we needed to aggregate *'United Kingdom'* values before since the dataset separated it. We can just purely use these data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_meat_consumption = pd.read_csv(meat_consumption_path)\n",
    "\n",
    "uk_meat_consumption = uk_meat_consumption[uk_meat_consumption['MEASURE'] == 'THND_TONNE']\n",
    "uk_meat_consumption = uk_meat_consumption[ (uk_meat_consumption['TIME'] >= 2004) & (uk_meat_consumption['TIME'] < 2019)]\n",
    "uk_meat_consumption = uk_meat_consumption[ (uk_meat_consumption['LOCATION'] == 'GBR')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_meat_consumption = uk_meat_consumption.groupby(['TIME', 'SUBJECT'])['Value'].sum().unstack(level=1)\n",
    "uk_meat_consumption['all_consumption'] = ( \n",
    "                                    (0.7 * uk_meat_consumption['BEEF']) +\n",
    "                                    (0.78 * uk_meat_consumption['PIG']) +\n",
    "                                    (0.88 * (uk_meat_consumption['SHEEP'] + uk_meat_consumption['POULTRY'])))\n",
    "uk_meat_consumption['years'] = uk_meat_consumption.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_population_from_2004_to_2018_in_billions = [59.95, 60.41, 60.83, 61.32, 61.82, 62.26, 62.76, 63.18, 63.7, 64.11, 64.6, 65.11, 65.65, 66.04, 66.44]\n",
    "uk_meat_consumption['population'] = uk_population_from_2004_to_2018_in_billions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing thousands of tons (1'000 tonnes == 1'000'000 kg) by population (in millions) will give us kg/person\n",
    "uk_meat_consumption['meat consumption (kg/person)'] = uk_meat_consumption['all_consumption']/uk_meat_consumption['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unecessary columns\n",
    "columns_to_drop = ['BEEF', 'PIG', 'POULTRY', 'SHEEP', 'all_consumption', 'population']\n",
    "uk_meat_consumption = uk_meat_consumption.drop(columns = columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_meat_consumption['Area'] = 'United Kingdom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variation column\n",
    "value_to_sub = get_value_of_2004(uk_meat_consumption)\n",
    "uk_meat_consumption['Variation'] = uk_meat_consumption['meat consumption (kg/person)'] - value_to_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 DE meat consumption (Germany)\n",
    "\n",
    "In order to get these datas, we need to merge two datasets:\n",
    "\n",
    "- From 2004 to 2008: [link](http://www.fao.org/faostat/en/?#data/FBS/visualize)\n",
    "\n",
    "- From 2008: [link](https://de.statista.com/statistik/daten/studie/36573/umfrage/pro-kopf-verbrauch-von-fleisch-in-deutschland-seit-2000/)\n",
    "\n",
    "Population data: [Eurostat](https://ec.europa.eu/eurostat/en/web/population-demography-migration-projections/statistics-illustrated)\n",
    "\n",
    "We used the overlap years between these two datasets to be sure that data is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted data\n",
    "data = [[2004, 84.4],[2005, 83.9],[2006, 84.3],[2007, 87.9],[2008, 89.8],[2009, 90.1],[2010, 91.2],[2011, 91.4],[2012, 88.8],[2013, 89],[2014, 89.4],[2015, 89.9],[2016, 89.8],[2017, 88.1],[2018, 88.6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "germany_meat_consumption = pd.DataFrame(data, columns = ['years', 'meat consumption (kg/person)']) \n",
    "# add Germany as country\n",
    "germany_meat_consumption['Area'] = 'Germany'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Variation column\n",
    "value_to_sub = get_value_of_2004(germany_meat_consumption)\n",
    "germany_meat_consumption['Variation'] = germany_meat_consumption['meat consumption (kg/person)'] - value_to_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 PT meat consumption (Portugal)\n",
    "\n",
    "Same principle as for the german datasets:\n",
    "\n",
    "- From  2004 to 2013: [link](http://www.fao.org/faostat/en/?#data/FBS/visualize)\n",
    "\n",
    "- From 2014: [link](https://www.ine.pt/xportal/xmain?xpid=INE&xpgid=ine_indicadores&contecto=pi&indOcorrCod=0000211&selTab=tab0)\n",
    "\n",
    "Population data: [Eurostat](https://ec.europa.eu/eurostat/en/web/population-demography-migration-projections/statistics-illustrated)\n",
    "\n",
    "Again: We used the overlap years between these two datasets to be sure that data is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[2004, 906/10.47],[2005, 918/10.49],[2006, 947/10.51],[2007, 1022/10.53],[2008, 1010/10.55],[2009, 1020/10.56],[2010, 1019/10.57],[2011, 986/10.57],[2012, 965/10.54],[2013, 966/10.49],[2014, 108.2],[2015, 111.2],[2016, 113.0],[2017, 113.8],[2018, 117.4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame \n",
    "portugal_meat_consumption = pd.DataFrame(data, columns = ['years', 'meat consumption (kg/person)']) \n",
    "# add Portugal as country\n",
    "portugal_meat_consumption['Area'] = 'Portugal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Variation column\n",
    "value_to_sub = get_value_of_2004(portugal_meat_consumption)\n",
    "portugal_meat_consumption['Variation'] = portugal_meat_consumption['meat consumption (kg/person)'] - value_to_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 FR meat consumption (France)\n",
    "\n",
    "Dataset: [link](https://www.franceagrimer.fr/Eclairer/Etudes-et-Analyses/Consommation-des-produits-carnes-en-2018)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_consumption_path = path + 'fr_consumption.csv'\n",
    "french_consumption = pd.read_csv(french_consumption_path)\n",
    "# cleaning\n",
    "french_consumption = french_consumption.drop(columns = ['nb Hab'])\n",
    "# constructing (renaming)\n",
    "french_consumption.columns = ['years', 'meat consumption (kg/person)']\n",
    "french_consumption['Area'] = 'France'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Variation column\n",
    "value_to_sub = get_value_of_2004(french_consumption)\n",
    "french_consumption['Variation'] = french_consumption['meat consumption (kg/person)'] - value_to_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 SVK meat consumption (Slovakia)\n",
    "\n",
    "Dataset: [link](http://datacube.statistics.sk/#!/view/en/VBD_SLOVSTAT/ps2041rs/v_ps2041rs_00_00_00_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slovakia_consumption_path = path + 'slovakia_consumption_trial.csv'\n",
    "# separator is \";\"\n",
    "slovakia_consumption = pd.read_csv(slovakia_consumption_path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only meat\n",
    "slovakia_consumption = slovakia_consumption[ slovakia_consumption['INDEX'] == 'Meat total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns (index, txt_value and all years before 2004)\n",
    "columns_to_drop = ['INDEX', 'TXT_VALUE']\n",
    "columns_to_drop += [str(x) for x in range(1990, 2004)]\n",
    "\n",
    "# years column to keep\n",
    "years_column = [str(x) for x in range(2004, 2019)]\n",
    "slovakia_consumption.drop(columns=columns_to_drop)\n",
    "\n",
    "# we need to melt in order to have the years inside a column instead of a column per year\n",
    "slovakia_consumption = pd.melt(slovakia_consumption.drop(columns=columns_to_drop), id_vars=[], value_vars=years_column)\n",
    "slovakia_consumption.columns = ['years', 'meat consumption (kg/person)']\n",
    "slovakia_consumption['Area'] = 'Slovakia'\n",
    "\n",
    "# convert to float (cleaning since dataset contained commas instead of dots on values)\n",
    "slovakia_consumption['meat consumption (kg/person)'] = [float(el.replace(',','.')) for el in slovakia_consumption['meat consumption (kg/person)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must do it to compare them while building variation (comparison between ints)\n",
    "slovakia_consumption['years'] = slovakia_consumption['years'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Variation column\n",
    "value_to_sub = get_value_of_2004(slovakia_consumption)\n",
    "slovakia_consumption['Variation'] = slovakia_consumption['meat consumption (kg/person)'] - value_to_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6 SVN meat consumption (Slovenia)\n",
    "\n",
    "Dataset: [visualize](https://www.stat.si/StatWeb/en/News/Index/8111), [data](https://pxweb.stat.si/SiStatDb/pxweb/sl/30_Okolje/30_Okolje__15_kmetijstvo_ribistvo__12_prehranske_bilance__02_15635_koled_bilance/1563501S.px/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slovenia_consumption_path = path + 'slovenia_consumption.csv'\n",
    "slovenia_consumption = pd.read_csv(slovenia_consumption_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_column = [x for x in range(2004, 2019)]\n",
    "slovenia_consumption.columns = years_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slovenia_consumption = pd.melt(slovenia_consumption, id_vars=[], value_vars=years_column)\n",
    "slovenia_consumption.columns = ['years', 'meat consumption (kg/person)']\n",
    "slovenia_consumption['Area'] = 'Slovenia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Variation column\n",
    "value_to_sub = get_value_of_2004(slovenia_consumption)\n",
    "slovenia_consumption['Variation'] = slovenia_consumption['meat consumption (kg/person)'] - value_to_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.7 SWE meat consumption (Sweden)\n",
    "\n",
    "Dataset: [link](http://statistik.sjv.se/PXWeb/pxweb/sv/Jordbruksverkets%20statistikdatabas/Jordbruksverkets%20statistikdatabas__Konsumtion%20av%20livsmedel/JO1301K2.px/?rxid=5adf4929-f548-4f27-9bc9-78e127837625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweden_consumption_path = path + 'sweden_meat_consumption_total.csv'\n",
    "sweden_consumption = pd.read_csv(sweden_consumption_path, sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweden_consumption = sweden_consumption.dropna().drop(columns=['Tabelluppgifter'])\n",
    "# only have until 2017\n",
    "years_column = [str(x) for x in range(2004, 2018)] \n",
    "sweden_consumption = pd.melt(sweden_consumption, id_vars=[], value_vars=years_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweden_consumption.columns = ['years', 'meat consumption (kg/person)']\n",
    "sweden_consumption['years'] = sweden_consumption['years'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweden_consumption['Area'] = 'Sweden'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Variation column\n",
    "value_to_sub = get_value_of_2004(sweden_consumption)\n",
    "sweden_consumption['Variation'] = sweden_consumption['meat consumption (kg/person)'] - value_to_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.8 POL meat consumption (Poland)\n",
    "\n",
    "We need to combine two datasets:\n",
    "\n",
    "- From  2004 to 2013: [link](http://www.fao.org/faostat/en/?#data/FBS/visualize)\n",
    "\n",
    "- From 2014: [link](https://www.pigprogress.net/World-of-Pigs1/Articles/2019/2/Poland-Once-thriving-now-fragmented-387324E/)\n",
    "\n",
    "Population: [worldometers](https://www.worldometers.info/world-population/poland-population/)\n",
    "\n",
    "Again: We used the overlap years between these two datasets to be sure that data is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[2004, 2968/38.4],[2005, 2949/38.37],[2006, 2961/38.35],[2007, 3036/38.35],[2008, 2927/38.35],[2009, 3002/38.35],[2010, 2987/38.32],[2011, 3038/38.28],[2012, 2941/38.23],[2013, 2968/38.16],[2014, 73.6],[2015, 75],[2016, 76]]\n",
    "\n",
    "poland_consumption = pd.DataFrame(data, columns = ['years', 'meat consumption (kg/person)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poland_consumption['Area'] = 'Poland'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Variation column\n",
    "value_to_sub = get_value_of_2004(poland_consumption)\n",
    "poland_consumption['Variation'] = poland_consumption['meat consumption (kg/person)'] - value_to_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.9 Merge above dataframes and plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames = uk_meat_consumption.append([\n",
    "    germany_meat_consumption,\n",
    "    portugal_meat_consumption,\n",
    "    french_consumption,\n",
    "    slovakia_consumption,\n",
    "    slovenia_consumption,\n",
    "    sweden_consumption,\n",
    "    poland_consumption],\n",
    "    ignore_index=True, sort=False)\n",
    "\n",
    "# cleaning data (some are str others are int/floats)\n",
    "all_frames['years'] = all_frames['years'].apply(lambda x: int(x))\n",
    "all_frames['meat consumption (kg/person)'] = all_frames['meat consumption (kg/person)'].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(all_frames, x=\"years\", y='meat consumption (kg/person)', color='Area')\n",
    "fig.update_xaxes(title_text='Years')\n",
    "fig.update_yaxes(title_text='meat consumption (kg/person)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to see the variation, for each country, we will substract the value from 2004. Thus, we will have the variations after 2004 only and it will allow us to have see the variation in a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = all_frames['Variation'].min()\n",
    "max_val =  all_frames['Variation'].max()\n",
    "\n",
    "fig = px.choropleth(all_frames, \n",
    "                    locations=\"Area\", \n",
    "                    scope=\"europe\", \n",
    "                    locationmode = 'country names', \n",
    "                    color='Variation', \n",
    "                    hover_name=\"Area\", \n",
    "                    animation_frame=\"years\", \n",
    "                    range_color=[min_val, max_val])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Climate Change awareness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Climate Change awareness of a population is difficult to measure. Due to a lack of survey to measure it, we use three different data to have a better look of the global trend of each EU country.\n",
    "\n",
    "- Google Trend on \"Climate change\" and \"Globalwarming\" topics\n",
    "- Eurobarometer a survey about \"what do you think are the two most important issues facing the EU at the moment?\"\n",
    "- Media Coverage about Climate change in some EU Countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#find google data\n",
    "###\n",
    "\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "#list topics \n",
    "climate_change_topic = [\"/m/0cs9q\"]\n",
    "global_warming_topic = [\"/m/0d063v\"]\n",
    "kw_list = [climate_change_topic,global_warming_topic]\n",
    "\n",
    "#import every data from google trend \n",
    "for x in range(0, len(kw_list)):\n",
    "    \n",
    "    #adding just the first country \n",
    "    pytrends.build_payload(kw_list[x], cat=0, timeframe='all', geo=country_list[0], gprop='')\n",
    "    pytrends.interest_over_time()\n",
    "    newDataframe = pytrends.interest_over_time()[kw_list[x]]\n",
    "    listColumn = []\n",
    "    listColumn.append(country_list[0])\n",
    "        \n",
    "    #adding other country\n",
    "    for y in range(1, len(country_list)): \n",
    "        pytrends.build_payload(kw_list[x], cat=0, timeframe='all', geo=country_list[y], gprop='')\n",
    "        ledata = pytrends.interest_over_time()\n",
    "        \n",
    "        #verify if we have data\n",
    "        if not ledata.empty:\n",
    "            ledata.drop(ledata.columns[len(ledata.columns)-1], axis=1, inplace=True)\n",
    "            newDataframe = pd.concat([newDataframe, ledata], axis=1, join='inner')\n",
    "            listColumn.append(country_list[y])\n",
    "\n",
    "    \n",
    "    newDataframe.columns = listColumn\n",
    "    \n",
    "    #remove first 21 months because of strange values \n",
    "    newDataframe = newDataframe[21:] \n",
    "    newDataframe.to_pickle(\"./data_martin/GoogleTrend\"+str(x)+\".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read pickles Data, \n",
    "df_climate_change = pd.read_pickle(\"./data_martin/GoogleTrend3.pkl\")\n",
    "df_global_warming = pd.read_pickle(\"./data_martin/GoogleTrend5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lines(df_global_warming+df_climate_change,25,\"Interest over time of Climate change and Global Warming \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotByGroup((df_climate_change+df_global_warming), 'Visualization Google Trend \"Global warming\" and \"Climate_change for one group', n_clusters=2, method='kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global tendancy about Climate change and Global Warming\n",
    "plotGlobalTrend(df_global_warming+df_climate_change,15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eurobarometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation data eurobarometer \n",
    "my_sheet = 'Sheet1'\n",
    "file_name = \"./data_martin/europa_survey/AT.xlsx\"\n",
    "df = read_excel(file_name, sheet_name = my_sheet)\n",
    "eurobarometer = df[[\"Date\"]]\n",
    "\n",
    "for country in country_list:\n",
    "    file_name = \"./data_martin/europa_survey/\"+country+\".xlsx\"\n",
    "    df = read_excel(file_name, sheet_name = my_sheet)\n",
    "    eurobarometer = pd.concat([eurobarometer, df[[\"Climate change\"]]], axis=1, join='inner')\n",
    "\n",
    "eurobarometer.columns = [\"Date\"]+country_list\n",
    "eurobarometer.index = eurobarometer[\"Date\"]\n",
    "eurobarometer = eurobarometer.drop(['Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global trend about Eurobaromter \n",
    "plotGlobalTrend(df_global_change_norm,5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMapSlider(eurobarometer,\"title\",0.46,0,\"% population thinks about it's one of the most important threat\",1300,900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Media coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sheet = 'Sheet2'\n",
    "file_name = \"./data_martin/coverage_media.xlsx\"\n",
    "coverageMedia = read_excel(file_name, sheet_name = my_sheet)\n",
    "coverageMedia = coverageMedia.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverageMedia_norm = coverageMedia.copy()\n",
    "for x in range(0,22):\n",
    "        coverageMedia_norm.iloc[2:,x] = coverageMedia_norm.iloc[2:,x]/coverageMedia_norm.iloc[2:,x].max()\n",
    "        \n",
    "coverageMedia_norm.loc[:,\"Total norm\"] = coverageMedia_norm.sum(axis=1)\n",
    "\n",
    "fig = go.Figure()\n",
    "df = coverageMedia_norm.loc[:,\"Total norm\"]\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df, mode='lines',name=x))\n",
    "fig.update_layout(title_text=\"Media coverage of Climate change/Global warming in EU\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Economic activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Economic considerations could play a role in determining people's meat consumption. In this section we gather data relating to the global macroeconomic situation of a country as well as economic information relating to households.\n",
    "The data is from OECD.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_Q = \"data_nico_quarterly/\"\n",
    "PATH_H = \"data_nico_household/\"\n",
    "names_q = [name for name in os.listdir(PATH_Q) if \".csv\" in name]\n",
    "names_h = [name for name in os.listdir(PATH_H) if \".csv\" in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_cols(df, value_name):\n",
    "    df = df.rename(columns={\"Value\": value_name})\n",
    "    return df.drop(['INDICATOR', 'SUBJECT','MEASURE','FREQUENCY','Flag Codes'], axis=1)\n",
    "\n",
    "def generate_df(csv_names,path):\n",
    "    df = None\n",
    "    str_end = len(\".csv\")\n",
    "    for name in csv_names:\n",
    "        if df is None:\n",
    "            df = proc_cols(pd.read_csv(path+name),name[:-str_end])\n",
    "        else:\n",
    "            new_df = proc_cols(pd.read_csv(path+name),name[:-str_end])\n",
    "            df = pd.merge(df, new_df,  how='outer', left_on=['LOCATION','TIME'], right_on = ['LOCATION','TIME'])\n",
    "    return df\n",
    "\n",
    "def df_date_format(df):\n",
    "    return df.replace({'-Q1':'-01-01','-Q2':'-04-01','-Q3':'-07-01','-Q4':'-10-01'}, regex=True)\n",
    "\n",
    "#adds date format and only starting from 2004\n",
    "def df_date_format_yearly(df):\n",
    "    df = df[df[\"TIME\"] >= 2004].copy() #copy for warning\n",
    "    df[\"TIME\"] = df[\"TIME\"].astype(str) + \"-01-01\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first gather information about unemployment and gdp growth as a proxy for the overall macroeconmic situation of countries (ie are they in a recession)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_df(names_q,PATH_Q)\n",
    "df_hur = df_date_format(df[['LOCATION','TIME','HUR']])\n",
    "df_gdp = df_date_format(df[['LOCATION','TIME','GDP_growth']])\n",
    "df_hur = df_hur.pivot_table(values='HUR', index='TIME', columns='LOCATION')\n",
    "df_gdp = df_gdp.pivot_table(values='GDP_growth', index='TIME', columns='LOCATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the first dataframe. It has the unemployement rate of each country for quarters starting in 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hur.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lines(df_hur,0,\"Unemployement rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a fall until 2008, corresponding to the debt crisis in Europe. Following, we see a strong spike in unemployment, especially in Spain and Greece.\n",
    "We can try to group countries with similar unemployement pattern using correlation distance and hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_4_GROUPS = 0.65\n",
    "df_corr_hur = df_hur.corr(method ='spearman')\n",
    "idx = getIdx(df_corr_hur,VAL_4_GROUPS)\n",
    "plotDifferentGroup(idx,df_hur,0,\"Unemployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note that that these four groups have the following characteristics: group 1 has a fairly constant unemployment, group 2 has a peak around 2014, group 3 peaks around 2010, and group 4 has an increased but fairly constant unemployment during the 2010-2014 period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next data we gathered relates to economic information about households."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_df(names_h,PATH_H)\n",
    "df = df_date_format_yearly(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize one of these values, for instance household debt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"House_debt\"\n",
    "df_debt = df[[\"LOCATION\",\"TIME\",column]].pivot_table(values=column, index='TIME', columns='LOCATION')\n",
    "plot_lines(df_debt,0,\"Household debt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Animal care"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same reason as the global ecology awareness, the interest about animal care is hard to measure.\n",
    "We gathered data from Google Trends over multiple subjects:\n",
    "- animal care\n",
    "- L214 (French association for animal protection)\n",
    "- slaughtering\n",
    "- specism\n",
    "- vegan cook\n",
    "- vegetarism\n",
    "- veganism\n",
    "- meat substitue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrendReq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-410e7c3c10ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpytrends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrendReq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en-US'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#topics list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkw_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"/m/032nch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#subject: animal care\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TrendReq' is not defined"
     ]
    }
   ],
   "source": [
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "#topics list \n",
    "kw_list = []\n",
    "kw_list.append([\"/m/032nch\"]) #subject: animal care\n",
    "kw_list.append([\"l214\"]) #keyword: l214 (French animal care association)\n",
    "kw_list.append([\"/m/047v0jr\"]) #slaughtering\n",
    "kw_list.append([\"/m/07628\"]) #specism\n",
    "kw_list.append([\"/m/07_lq\"]) #vegan cook\n",
    "kw_list.append([\"/m/07_jd\"]) #vegetarism\n",
    "kw_list.append([\"/m/07_hy\"]) #veganism\n",
    "kw_list.append([\"/m/020953\"]) #meat substitute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading google trend data for subject in kw_list\n",
    "for x in range(len(kw_list)):\n",
    "    \n",
    "    #adding just the first one\n",
    "    pytrends.build_payload(kw_list[x], cat=0, timeframe='all', geo=country_list[0], gprop='')\n",
    "    pytrends.interest_over_time()\n",
    "    newDataframe = pytrends.interest_over_time()[kw_list[x]]\n",
    "    listColumn = []\n",
    "    listColumn.append(country_list[0])\n",
    "        \n",
    "    for y in range(1, len(country_list)): \n",
    "        pytrends.build_payload(kw_list[x], cat=0, timeframe='all', geo=country_list[y], gprop='')\n",
    "        ledata = pytrends.interest_over_time()\n",
    "        if not ledata.empty:\n",
    "            ledata.drop(ledata.columns[len(ledata.columns)-1], axis=1, inplace=True)\n",
    "            newDataframe = pd.concat([newDataframe, ledata], axis=1, join='inner')\n",
    "            listColumn.append(country_list[y])\n",
    "\n",
    "    newDataframe.columns = listColumn\n",
    "    newDataframe = newDataframe[19:] #remove first strange Data\n",
    "    newDataframe.to_pickle(\"./data_vinc/GoogleTrend\"+str(x)+\".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "#df_animal_cruelty = pd.read_pickle(\"./data_vinc/GoogleTrend0.pkl\")\n",
    "df_l214 = pd.read_pickle(\"./data_vinc/GoogleTrend1.pkl\")\n",
    "#df_abattage = pd.read_pickle(\"./data_vinc/GoogleTrend2.pkl\")\n",
    "df_specism = pd.read_pickle(\"./data_vinc/GoogleTrend3.pkl\")\n",
    "df_vegan_cook = pd.read_pickle(\"./data_vinc/GoogleTrend4.pkl\")\n",
    "df_vegetarism = pd.read_pickle(\"./data_vinc/GoogleTrend5.pkl\")\n",
    "df_veganism = pd.read_pickle(\"./data_vinc/GoogleTrend6.pkl\")\n",
    "df_meat_substitute = pd.read_pickle(\"./data_vinc/GoogleTrend7.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lines((df_veganism+df_vegetarism+df_vegan_cook), 0, \"Interest over time of vegetarism/veganism and vegan recipes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lines((df_veganism+df_vegetarism+df_vegan_cook)[['IT', 'FR', 'GR', 'PT', 'PL']], 0, \"Interest over time of vegetarism/veganism and vegan recipes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the interest for this topic increased last 10 years.\n",
    "The most interesting fact with google trend is the spikes we have at a precise month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lines(df_l214[['FR']], 7, \"Interest over time of l214 in France\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that something happened in France in April 2016 with the association L214, even the research for meat substitute has increased at that moment. What would be interesting is to find the exact event that happened at that moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lines(df_meat_substitute[['FR']], 7, \"Interest over time of vegetarism/veganism and vegan recipes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the research for the subject 'meat substitute' increased in April 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are also some curious curves, in Italy the interest for veganism increase significantly between 2013 and 2014. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lines(df_veganism[['IT']], 7, \"Interest over time of veganism in Italy\")å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some event clearly happenened when those researches exploded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can see some similar behaviours in those interests. K-means algorithm might be a first idea to cluster the differents countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotByGroup((df_veganism+df_vegetarism+df_vegan_cook), 'title temp', n_clusters=2, method='kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotByGroup((df_veganism+df_vegan_cook), 'title temp', n_clusters=3, method='kmeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we display the countries that are grouped together, we can see that they are geographicaly close to each other. It look like the cultural background of the countries has a lot of influence on the interest over our  topics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
